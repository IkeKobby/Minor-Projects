{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_cvuAZkL4mU"
   },
   "source": [
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vkx2pinL4mW"
   },
   "source": [
    "- Standard Modules Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8o5TSkFlL4mX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings. simplefilter(action = \"ignore\", category = Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lWfyWwIBL4mZ"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"fraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "9N-yaUUxL4mZ",
    "outputId": "e0852dea-c6c4-4920-9a6e-a4c2e0f8d477"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1wYy6CzL4mb"
   },
   "source": [
    "- We shall explore the data to see if we have some cleaning to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qvBeosAdL4mb",
    "outputId": "596608e3-6eaf-4609-deff-648e29ee0d51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We shall check for the number of features and observations we have in our datasets.\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJmzAuMQL4mb"
   },
   "source": [
    "- We have $ 284, 807 $ observations against $30$ features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsdEo0hdL4mc"
   },
   "source": [
    "We will visualize the data distribution from the Class varibale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "JX9qJ0W1L4mc",
    "outputId": "bf479372-9717-4320-d035-4e21a79727dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Class', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## We want to see if we have a fair distribution of our dataset for a model to learn from.\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(data['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYFt13TPL4md"
   },
   "source": [
    "- It is clearly seen by the count plot that the data distribution for the Class is higher in class 1 than class 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Class', ylabel='Density'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(data['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the distribution plot we can see that almost all our data is highly densed on one class where the other class is approximately zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness: 23.997579\n",
      "Kurtosis: 573.887843\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm, skew\n",
    "print(\"Skewness: %f\" % data['Class'].skew())\n",
    "print(\"Kurtosis: %f\" % data['Class'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skewness is a measure of the symmetry in a distribution.  A symmetrical dataset will have a skewness equal to 0.  So, a normal distribution will have a skewness of 0.   Skewness essentially measures the relative size of the two tails. Hence;\n",
    "\n",
    "- If the skewness is between -0.5 and 0.5, the data are fairly symmetrical\n",
    "- If the skewness is between -1 and â€“ 0.5 or between 0.5 and 1, the data are moderately skewed\n",
    "- If the skewness is less than -1 or greater than 1, the data are highly skewed and this is exactly our case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similary;\n",
    "Kurtosis is a measure of the combined sizes of the two tails.  It measures the amount of probability in the tails.  The value is often compared to the kurtosis of the normal distribution, which is equal to 3.  \n",
    "- If the kurtosis is greater than 3, then the dataset has heavier tails than a normal distribution (more in the tails).  \n",
    "- If the kurtosis is less than 3, then the dataset has lighter tails than a normal distribution (less in the tails). \n",
    "- Therefore we can conclude that the dataset has heavier tails than a normally distributed data and hence we will handle such cases strategically in curb the robustness in the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do some descriptive analysis to check the means and standard deviation for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "j6thb5f3L4mh",
    "outputId": "2c697001-69f4-4db3-dd54-2c199044a050"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i21UAXhJL4me",
    "outputId": "698f26f3-d7a7-4077-ac43-269ab27ae5ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      float64\n",
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "Class       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking for the types of inputs in our data\n",
    "data.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPlmhO2UL4md",
    "outputId": "79ee333d-28c9-45cd-94ad-0e0f0fc49437"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check for nan values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_yW6_GZL4me"
   },
   "source": [
    "- Fortunately we have no 'Nan' values to deal with in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNFgziPKL4mf"
   },
   "source": [
    "- We also have no object types to handle. This sounds good so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YxD69mjZL4mg",
    "outputId": "ff1c6a56-9945-42a2-e7c1-2ea5052f1a7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tYH_Ot4L4mh"
   },
   "source": [
    "- The data is highly skewed towards the class \"0\" category. However, we shall check for accuracy level for the three models first and see if there is the need for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCi3bpw3L4mh"
   },
   "source": [
    "- We check for data summary on descriptive analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImEinjobL4mi"
   },
   "source": [
    "- Quickly we shall use heatmap to check feature correlation in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Nlq_PCO_L4mj"
   },
   "outputs": [],
   "source": [
    "cols = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlBmkAEeL4mj"
   },
   "source": [
    "- We split data into train and test for fitting and accuracy check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "nnNQnvnTL4mj"
   },
   "outputs": [],
   "source": [
    "### creating a copy of the data\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Y6W24VzTL4mk"
   },
   "outputs": [],
   "source": [
    "### Getting data ready for training and testing\n",
    "\n",
    "X = df.drop(columns = ['Class', 'Time'])  ### extracting the features into 'X'\n",
    "y = df[['Class']]   #### also extracting the response into the vector 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Bs8trP_qL4mk"
   },
   "outputs": [],
   "source": [
    "### standard train and test importation from the sci-kit learn for data splitting.\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X_train,X_test,y_train,y_test = tts(X,y, train_size = 0.7, random_state = 22)  ### maintaining train-size of 80% after splitting with 20% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oJw3fZ-QL4ml",
    "outputId": "c43ff24f-b366-4e30-c3c8-ffb5fb40c614"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199364, 29), (85443, 29), (199364, 1), (85443, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape  ### Checking the size of train and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SGbQqcpnL4mm",
    "outputId": "f0316b3b-1496-4075-ac56-1459f6dc4db0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199020\n",
       "1       344\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf = pd.DataFrame(y_train)\n",
    "yf['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split(X,y):\n",
    "    return train_test_split(X,y, test_size=0.7, random_state=58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o83s2vEYL4mm"
   },
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RJl9agjfL4mn"
   },
   "outputs": [],
   "source": [
    "### importing the classifier from the ensemble library within sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "p0HRyR4vL4mn"
   },
   "outputs": [],
   "source": [
    "### instantiating the models\n",
    "class models:\n",
    "    def __init__(self, fun):\n",
    "        self.fun = fun\n",
    "    \n",
    "    def random_forest(fun):\n",
    "        X_train, X_test, y_train, y_test = fun\n",
    "        RFC = RandomForestClassifier(n_estimators = 100,random_state = 58)\n",
    "        RFC.fit(X_train,y_train)\n",
    "        Random_Forest_score = RFC.score(X_test,y_test)\n",
    "        return Random_Forest_score,RFC\n",
    "\n",
    "    def support_vector_machine(fun):\n",
    "        X_train, X_test, y_train, y_test = fun\n",
    "        svm_clf = SVC(random_state = 58)\n",
    "        svm_clf.fit(X_train,y_train)\n",
    "        svm_score = svm_clf.score(X_test,y_test)\n",
    "        return svm_score, svm_clf\n",
    "\n",
    "\n",
    "    def ann():\n",
    "        model = keras.Sequential([\n",
    "        keras.layers.Dense(units = 500, input_shape = (29,),kernel_initializer = 'he_uniform', activation = 'relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(units = 200,kernel_initializer = 'he_uniform', activation = 'relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(units=1,kernel_initializer = 'glorot_uniform', activation = 'sigmoid')\n",
    "            ])  #### ANN with two hidden layers.\n",
    "\n",
    "        model.compile(optimizer = 'adam', \n",
    "                  loss = 'binary_crossentropy', \n",
    "                  metrics = ['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting score and model for SVM classifier for classification report\n",
    "svm_score, svm = models.support_vector_machine(split(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SUPPORT VECTOR MACHINE\n",
    "\n",
    "### Getting score and model for SVM classifier for classification report\n",
    "svm_score, svm = models.support_vector_machine(split(X,y))\n",
    "\n",
    "\n",
    "### We shall use the split function to make predictions and print classification report\n",
    "### To check for the model precision, recall and f1-score\n",
    "X_train, X_test, y_train,y_test = split(X,y)\n",
    "svm_preds = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test,svm_preds))\n",
    "print(classification_report(y_test, svm_preds))\n",
    "print(svm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[198997     20]\n",
      " [   249     99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    199017\n",
      "           1       0.83      0.28      0.42       348\n",
      "\n",
      "    accuracy                           1.00    199365\n",
      "   macro avg       0.92      0.64      0.71    199365\n",
      "weighted avg       1.00      1.00      1.00    199365\n",
      "\n",
      "0.9986507160233742\n"
     ]
    }
   ],
   "source": [
    "### We shall use the split function to make predictions and print classification report\n",
    "### To check for the model precision, recall and f1-score\n",
    "X_train, X_test, y_train,y_test = split(X,y)\n",
    "svm_preds = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test,svm_preds))\n",
    "print(classification_report(y_test, svm_preds))\n",
    "print(svm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Support Vector Machine irrespective of the high score has a very poor performance for recall and f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm_svm = confusion_matrix(y_test,svm_preds)\n",
    "# # plt.figure(figsize = (6,4))\n",
    "# # sns.heatmap(cm_svm,annot = True,\n",
    "# #             linewidths = .5,\n",
    "# #             center = 0,\n",
    "# #             cbar = False, \n",
    "# #             cmap = None)\n",
    "# # plt.xlabel(\"Predicted Class\")\n",
    "# # plt.ylabel(\"True Class\")\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Getting score and model for classification report on the model performance\n",
    "rfc_score, rfc = models.random_forest(split(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[198991     26]\n",
      " [    85    263]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    199017\n",
      "           1       0.91      0.76      0.83       348\n",
      "\n",
      "    accuracy                           1.00    199365\n",
      "   macro avg       0.95      0.88      0.91    199365\n",
      "weighted avg       1.00      1.00      1.00    199365\n",
      "\n",
      "0.9994432322624333\n"
     ]
    }
   ],
   "source": [
    "### We shall use the split function to make predictions and print classification report\n",
    "### To check for the model precision, recall and f1-score\n",
    "\n",
    "X_train, X_test, y_train,y_test = split(X,y)\n",
    "rfc_preds = rfc.predict(X_test)\n",
    "print(confusion_matrix(y_test,rfc_preds))\n",
    "print(classification_report(y_test, rfc_preds))\n",
    "print(rfc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random forest has good performance and recall and f1-score is better than Support Vector Machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm_rfc = confusion_matrix(y_test,rfc_preds)\n",
    "# # plt.figure(figsize = (6,4))\n",
    "# # sns.heatmap(cm_rfc,annot = True,\n",
    "# #             linewidths = .5,\n",
    "# #             center = 0,\n",
    "# #             cbar = False, \n",
    "# #             cmap = None)\n",
    "# # plt.xlabel(\"Predicted Class\")\n",
    "# # plt.ylabel(\"True Class\")\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "855/855 [==============================] - 9s 10ms/step - loss: 0.3465 - accuracy: 0.9965 - val_loss: 0.1066 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "855/855 [==============================] - 9s 10ms/step - loss: 0.0986 - accuracy: 0.9980 - val_loss: 0.0185 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "855/855 [==============================] - 9s 10ms/step - loss: 0.0332 - accuracy: 0.9984 - val_loss: 0.0163 - val_accuracy: 0.9989\n",
      "Epoch 4/5\n",
      "855/855 [==============================] - 9s 10ms/step - loss: 0.0296 - accuracy: 0.9986 - val_loss: 0.0096 - val_accuracy: 0.9990\n",
      "Epoch 5/5\n",
      "855/855 [==============================] - 9s 10ms/step - loss: 0.0188 - accuracy: 0.9988 - val_loss: 0.0122 - val_accuracy: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faa80bad4f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### instantiating the ann from the class models and fitting for prediction\n",
    "ann = models.ann()\n",
    "ann.fit(X_train,y_train, batch_size = 100, validation_data=(X_test,y_test),epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6231/6231 [==============================] - 10s 2ms/step - loss: 0.0122 - accuracy: 0.9987\n",
      "[[199017      0]\n",
      " [   348      0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    199017\n",
      "           1       0.00      0.00      0.00       348\n",
      "\n",
      "    accuracy                           1.00    199365\n",
      "   macro avg       0.50      0.50      0.50    199365\n",
      "weighted avg       1.00      1.00      1.00    199365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### We shall use the split function to make predictions and print classification report\n",
    "### To check for the model precision, recall and f1-score\n",
    "\n",
    "X_train, X_test, y_train,y_test = split(X,y)\n",
    "ann.evaluate(X_test,y_test)\n",
    "ann_preds = ann.predict(X_test)\n",
    "ann_preds = [np.argmax(i) for i in ann_preds]\n",
    "print(confusion_matrix(y_test,ann_preds))\n",
    "print(classification_report(y_test, ann_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Artificial Neural Network does not perform better for our data structure. The model is not able to learn for the fraud class. Although is has a high accuracy precision, recall and f1-score is extremely poor and hence not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "TZY-MQZfL4my",
    "outputId": "e501c0ad-6dce-48ed-ad56-311e68e4bad0"
   },
   "outputs": [],
   "source": [
    "# cm_ann = confusion_matrix(y_test,ann_preds)\n",
    "# # plt.figure(figsize = (6,4))\n",
    "# # sns.heatmap(n_cm,annot = True,\n",
    "# #             linewidths = .5,\n",
    "# #             center = 0,\n",
    "# #             cbar = False, \n",
    "# #             cmap = None)\n",
    "# # plt.xlabel(\"Predicted Class\")\n",
    "# # plt.ylabel(\"True Class\")\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYJuKK5Z4zcR"
   },
   "source": [
    "- The confusion matrix shows that the predictions for the class 0 was not learned  by the neural network. We shall look for ways to improve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0uQIxdCL4mz"
   },
   "source": [
    "### Using stratifiedKFold sampling technique as a way of curbing the biasedness of the class distribution in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "2bVFsbhcL4mz"
   },
   "outputs": [],
   "source": [
    "## Converting the input and output dataframe into numpy arrays\n",
    "X_new,y_new = X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "G55Vu25DL4mz",
    "outputId": "b6a27001-a52a-4287-f895-8280658630d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56827    36]\n",
      " [   33    66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.65      0.67      0.66        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.82      0.83      0.83     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56824    39]\n",
      " [   12    87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.69      0.88      0.77        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.85      0.94      0.89     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56861     2]\n",
      " [   52    47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.96      0.47      0.64        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.98      0.74      0.82     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56863     0]\n",
      " [   22    77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      0.78      0.88        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       1.00      0.89      0.94     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56861     2]\n",
      " [   74    24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.92      0.24      0.39        98\n",
      "\n",
      "    accuracy                           1.00     56961\n",
      "   macro avg       0.96      0.62      0.69     56961\n",
      "weighted avg       1.00      1.00      1.00     56961\n",
      "\n",
      "[[56847    16]\n",
      " [   32    66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.80      0.67      0.73        98\n",
      "\n",
      "    accuracy                           1.00     56961\n",
      "   macro avg       0.90      0.84      0.87     56961\n",
      "weighted avg       1.00      1.00      1.00     56961\n",
      "\n",
      "[[56863     0]\n",
      " [   54    44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      0.45      0.62        98\n",
      "\n",
      "    accuracy                           1.00     56961\n",
      "   macro avg       1.00      0.72      0.81     56961\n",
      "weighted avg       1.00      1.00      1.00     56961\n",
      "\n",
      "[[56861     2]\n",
      " [   17    81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.98      0.83      0.90        98\n",
      "\n",
      "    accuracy                           1.00     56961\n",
      "   macro avg       0.99      0.91      0.95     56961\n",
      "weighted avg       1.00      1.00      1.00     56961\n",
      "\n",
      "[[56863     0]\n",
      " [   92     6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      0.06      0.12        98\n",
      "\n",
      "    accuracy                           1.00     56961\n",
      "   macro avg       1.00      0.53      0.56     56961\n",
      "weighted avg       1.00      1.00      1.00     56961\n",
      "\n",
      "[[56862     1]\n",
      " [   30    68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.99      0.69      0.81        98\n",
      "\n",
      "    accuracy                           1.00     56961\n",
      "   macro avg       0.99      0.85      0.91     56961\n",
      "weighted avg       1.00      1.00      1.00     56961\n",
      "\n",
      "[0.9987886661282961, 0.9990519995786665, 0.9986657537613455, 0.9990519829356929, 0.9983848598163656]\n",
      "[0.9991046662687406, 0.9996137776061234, 0.9991573181650603, 0.9996664384403364, 0.9994557679816014]\n"
     ]
    }
   ],
   "source": [
    " # Importing necessary libraries for the StratifiedKFold split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "SVM = SVC(random_state = 40)  ### instantiating the model with some necessary parameters\n",
    "RFC = RandomForestClassifier(n_estimators = 120, random_state = 58) ### instantiating our random_forest\n",
    "folds = StratifiedKFold(n_splits=5) ### instantiating the stratifiedkfold with 5 number of splits.\n",
    "\n",
    "### a function that takes the model, fit the model for each split and then computer the score\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "### initiating an empty list to record the score for each split\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "\n",
    "#### looping through all the splitted data and appending the score for each split using the get_score function.\n",
    "for train_index, test_index in folds.split(X,y): \n",
    "    X_train, X_test, y_train, y_test = X_new[train_index], X_new[test_index], y_new[train_index], y_new[test_index] \n",
    "    scores_svm.append(get_score(SVM, X_train, X_test, y_train, y_test))\n",
    "    scores_rf.append(get_score(RFC, X_train, X_test, y_train, y_test))\n",
    "    \n",
    "### printing out the scores\n",
    "print(scores_svm)\n",
    "print(scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "cEvJRJlb8bk8"
   },
   "outputs": [],
   "source": [
    "### A function that returns our artificial neural network. This shall reduce the cost of having to build for different sampling techniques\n",
    "def ANN():\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Dense(units = 500, input_shape = (29,),kernel_initializer = 'he_uniform', activation = 'relu'), \n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units = 200,kernel_initializer = 'he_uniform', activation = 'relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=1,kernel_initializer = 'glorot_uniform', activation = 'sigmoid')\n",
    "        ])  #### ANN with two hidden layers.\n",
    "\n",
    "    model.compile(optimizer = 'adam', \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "LQaN0MAJL4m0",
    "outputId": "2ad16b6a-81fb-4ad5-9d21-57c5f6dbd852"
   },
   "outputs": [],
   "source": [
    "# Using stratifiedKFold with different epochs and batch_size\n",
    "\n",
    "params = {'epochs':[50], 'batch_size':[100]}\n",
    "Evaluation_score = [] # recording each evaluation in all the iterations\n",
    "\n",
    "for epochs, batch_size in zip(params['epochs'], params['batch_size']):\n",
    "    for train_index, test_index in folds.split(X_new,y_new):\n",
    "        X_train, X_test, y_train, y_test = X_new[train_index], X_new[test_index], y_new[train_index], y_new[test_index]\n",
    "        model=ANN()\n",
    "        model.fit(X_train,y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        Evaluation_score.append(model.evaluate(X_test,y_test))\n",
    "print(Evaluation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Z5rhmhKL4m0"
   },
   "source": [
    "### Data statistics under the following \"Imbalance learning\" topics to conclude on the best model.\n",
    "\n",
    "1) Under Sampling \n",
    "\n",
    "2) Over Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGY6DgqlL4m0"
   },
   "source": [
    "# Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Let define a function for the two classifiers, SVM and Random Forest\n",
    "\n",
    "def rfc_sample(X_train_sample, y_train_sample,X_test,y_test):\n",
    "    rfc_us = RandomForestClassifier(n_estimators = 100, random_state=100)\n",
    "    rfc_us.fit(X_train_sample, y_train_sample)\n",
    "    \n",
    "    #### Now we use the model to make predictions on the entire data and then check for the precision, recall and fi-score\n",
    "    us_preds = rfc_us.predict(X_test)\n",
    "    print(confusion_matrix(y_test,us_preds))\n",
    "    print(classification_report(y_test, us_preds))\n",
    "    print(rfc_us.score(X_test,y_test))\n",
    "\n",
    "\n",
    "def svm_sample(X_train_sample, y_train_sample,X_test,y_test):\n",
    "    svm_all = SVC(random_state=60)\n",
    "    svm.fit(X_train_sample, y_train_sample)\n",
    "    #### Now we use the model to make predictions on the entire data and then check for the precision, recall and fi-score\n",
    "    us_preds = rfc_us.predict(X_test)\n",
    "    print(confusion_matrix(y_test,us_preds))\n",
    "    print(classification_report(y_test, us_preds))\n",
    "    print(rfc_us.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "QfIbTpTGL4m1"
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "CRLd9StUL4m1"
   },
   "outputs": [],
   "source": [
    "ns = NearMiss(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "eEBfS7J_L4m1"
   },
   "outputs": [],
   "source": [
    "### resampling the train data\n",
    "X_train_us, y_train_us = ns.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "fZ_uX20vL4m1",
    "outputId": "91d07685-06c8-49c6-f351-812557b764ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    199020\n",
      "1       344\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#### The composition of the data distribution before undersampling\n",
    "\n",
    "print(y_train['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "m4q1_jedL4m2",
    "outputId": "b1c526fd-c399-4140-d1bf-dce5f87dd897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    492\n",
      "1    492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### The composition of the data after the undersampling in the ratio 0.7\n",
    "print(y_train_us['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGrqMiEfL4m2"
   },
   "source": [
    "### RandomForestClassifier for Undersampled Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  549 84746]\n",
      " [    0   148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.01     85295\n",
      "           1       0.00      1.00      0.00       148\n",
      "\n",
      "    accuracy                           0.01     85443\n",
      "   macro avg       0.50      0.50      0.01     85443\n",
      "weighted avg       1.00      0.01      0.01     85443\n",
      "\n",
      "0.008157485107030418\n"
     ]
    }
   ],
   "source": [
    "rfc_sample(X_train_us, y_train_us, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Bg7KxF-L4m3"
   },
   "source": [
    "- Here after undersampling technique it is observed accuracy reduced which very obvious but most interestingly almost all the information were lost during the undersampling and hence leading to poor performance of the model for the class 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S48GBHZyL4m4"
   },
   "source": [
    "### Support Vector Classifier for Undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  549 84746]\n",
      " [    0   148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.01     85295\n",
      "           1       0.00      1.00      0.00       148\n",
      "\n",
      "    accuracy                           0.01     85443\n",
      "   macro avg       0.50      0.50      0.01     85443\n",
      "weighted avg       1.00      0.01      0.01     85443\n",
      "\n",
      "0.008157485107030418\n"
     ]
    }
   ],
   "source": [
    "svm_sample(X_train_us, y_train_us, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Support Vector Machine also performed very bad for precisiona and f1-score. Hence our undersampling technique does not favor our objectives here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FQQ_Y2vL4m6"
   },
   "source": [
    "### ANN for Undersampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "99/99 [==============================] - 10s 101ms/step - loss: 0.5668 - accuracy: 0.9289 - val_loss: 166.1357 - val_accuracy: 0.0664\n",
      "Epoch 2/10\n",
      "99/99 [==============================] - 9s 94ms/step - loss: 0.0745 - accuracy: 0.9817 - val_loss: 167.8307 - val_accuracy: 0.0762\n",
      "Epoch 3/10\n",
      "99/99 [==============================] - 9s 95ms/step - loss: 0.0470 - accuracy: 0.9858 - val_loss: 196.7368 - val_accuracy: 0.0525\n",
      "Epoch 4/10\n",
      "99/99 [==============================] - 9s 94ms/step - loss: 0.0436 - accuracy: 0.9878 - val_loss: 205.2281 - val_accuracy: 0.0454\n",
      "Epoch 5/10\n",
      "99/99 [==============================] - 9s 94ms/step - loss: 0.0560 - accuracy: 0.9827 - val_loss: 200.5938 - val_accuracy: 0.0525\n",
      "Epoch 6/10\n",
      "99/99 [==============================] - 9s 94ms/step - loss: 0.0209 - accuracy: 0.9959 - val_loss: 207.4711 - val_accuracy: 0.0458\n",
      "Epoch 7/10\n",
      "99/99 [==============================] - 9s 94ms/step - loss: 0.0312 - accuracy: 0.9919 - val_loss: 216.9597 - val_accuracy: 0.0385\n",
      "Epoch 8/10\n",
      "99/99 [==============================] - 9s 94ms/step - loss: 0.0334 - accuracy: 0.9939 - val_loss: 219.5352 - val_accuracy: 0.0406\n",
      "Epoch 9/10\n",
      "99/99 [==============================] - 9s 95ms/step - loss: 0.0290 - accuracy: 0.9929 - val_loss: 220.3342 - val_accuracy: 0.0384\n",
      "Epoch 10/10\n",
      "99/99 [==============================] - 9s 95ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 228.6647 - val_accuracy: 0.0339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faa7655e640>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Just call the ANN function\n",
    "model=ANN()\n",
    "model.fit(X_train_us,y_train_us, batch_size=10, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2671/2671 [==============================] - 4s 1ms/step - loss: 228.6651 - accuracy: 0.0339\n",
      "[[85295     0]\n",
      " [  148     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.00      0.00      0.00       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.50      0.50      0.50     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### We make predictions and check the metrics for the performance of the Artificial Neural Network.\n",
    "model.evaluate(X_test,y_test)\n",
    "ann_preds = model.predict(X_test)\n",
    "ann_us_preds = [np.argmax(i) for i in ann_preds]\n",
    "print(confusion_matrix(y_test,ann_us_preds))\n",
    "print(classification_report(y_test, ann_us_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vdk-MlxTL4m9"
   },
   "source": [
    "- Obviously, ANN seem biased towards the majority class for the undersample technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udmWh7E4L4m-"
   },
   "source": [
    "# Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "J5YfXTUHL4m-"
   },
   "outputs": [],
   "source": [
    "### Oversampling using RandomOverSampler\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "7af3yzLIL4m-"
   },
   "outputs": [],
   "source": [
    "# Oversampling with a ratio of 0.9 of minority class to majority class\n",
    "os = RandomOverSampler(sampling_strategy=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "S_qfzcJ3L4m-"
   },
   "outputs": [],
   "source": [
    "X_train_os, y_train_os = os.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "gLF0inXRL4m-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "0    284315\n",
      "1    255883\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y['Class'].value_counts())\n",
    "print(y_train_os['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest for Oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85295     0]\n",
      " [    0   148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       1.00      1.00      1.00       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       1.00      1.00      1.00     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "### We shall fit the new dataset and make predictions from the test split of our original data.\n",
    "rfc_sample(X_train_os, y_train_os, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This sampling technique seem to have outperformed the undersampling in an excellent way. The model has had enough data to make decision. And since precision, recall and f1-score has a very good performance here we can say that this technique and perhaps the model is so far good.\n",
    "- Best sampling technique for the particular dataset is evidenced by the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector for Oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "QozYpWAnL4m_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  549 84746]\n",
      " [    0   148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.01     85295\n",
      "           1       0.00      1.00      0.00       148\n",
      "\n",
      "    accuracy                           0.01     85443\n",
      "   macro avg       0.50      0.50      0.01     85443\n",
      "weighted avg       1.00      0.01      0.01     85443\n",
      "\n",
      "0.008157485107030418\n"
     ]
    }
   ],
   "source": [
    "svm_sample(X_train_os, y_train_os, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esU7M79AL4m_"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFp2cpFTL4nC"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTU20Q74L4nD"
   },
   "source": [
    "# Ensembled Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9C8ZGvg0L4nE"
   },
   "outputs": [],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_njgml-zL4nE"
   },
   "outputs": [],
   "source": [
    "easy = EasyEnsembleClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfI-lGQPL4nE"
   },
   "outputs": [],
   "source": [
    "easy.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8iBAx7JL4nE"
   },
   "outputs": [],
   "source": [
    "y_pred = easy.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test,y_pred))\n",
    "print(accuracy_score(Y_test,y_pred))\n",
    "print(classification_report(Y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "eCebb0tML4mq",
    "8Z5rhmhKL4m0",
    "vGY6DgqlL4m0",
    "pGrqMiEfL4m2",
    "S48GBHZyL4m4",
    "8FQQ_Y2vL4m6",
    "udmWh7E4L4m-",
    "xhG8P4TxL4m_",
    "rCEdY-kQL4nA",
    "GTU20Q74L4nD"
   ],
   "name": "data stats.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
